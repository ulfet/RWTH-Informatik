{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First home assignment Social Data Science"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Submit your solution by email to submission@cssh.rwth-aachen.de until 23.59pm on Wednesday, November 28th!\n",
    "Use \"[SDS] Submission Home Assignment 1\" as the email subject.\n",
    "\n",
    "You can (and should!) submit solutions in teams of up to three members.\n",
    "Please denote all members of the team with their student id and full name in the notebook as well as in the email body. Put all team members in email CC when submitting. Please submit only one email per team.\n",
    "\n",
    "Cite ALL your sources for coding this home assignment. In case of plagiarism (copying solutions from other teams or from the internet) ALL team members will be expelled from the course without warning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement multiple linear regression by gradient descent\n",
    "Your implementation should be based on numpy arrays. Your implementation can use functions from the numpy library.\n",
    "\n",
    "Your function should have the signature\n",
    "linear_regression_gd (X,y,learning_rate) and should return a tuple (mean_squared_error_of_solution, [list_of_optimum_parameters])\n",
    "Here, X is a numpy array with the values of the explanatory variables, and y is an array with the dependent variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "# expect our input to be in the same shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/8486294/how-to-add-an-extra-column-to-a-numpy-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "y = np.dot(X, np.array([[1], [2]])) + 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspiration: https://towardsdatascience.com/gradient-descent-in-python-a0d07285742f\n",
    "# X: numpy array with values of the explanatory variables\n",
    "# y: array with dependent variables\n",
    "def linear_regression_gd(X,y,learning_rate): \n",
    "    n_samples = (np.shape(X)[0])\n",
    "    p = np.shape(X)[1] # p is the number of variables in the multiple regression\n",
    "    b = np.ones((p+1,1)) #'guess' the initial values as zeros, +1 for the b_0 value\n",
    "    X = np.insert(X, 0, values=1, axis=1) # add a column of ones s.t. y=X*b\n",
    "    \n",
    "    # now the gradient descent:\n",
    "    for i in range(10000):\n",
    "        prediction = np.dot(X,b)\n",
    "        #print(prediction)\n",
    "        d_b = (-1)*np.dot(np.transpose(X),(2*(y-prediction))) # derivative w.r.t. b\n",
    "        #print(d_b)\n",
    "        b = b - 1/n_samples * learning_rate*d_b # b = b - learning_rate*gradient(f)\n",
    "        #print(b)\n",
    "\n",
    "    #return (mean_squared_error_of_solution,list_of_optimum_parameters)\n",
    "    return (np.mean((y-np.dot(X,b))**2), b) #np.mean((y-np.dot(X,b))**2), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.38399427584945e-14, array([[2.99999932],\n",
       "        [1.00000052],\n",
       "        [1.99999993]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_gd(X,y,0.01) #... should be 3,1,2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extend your previous code to implement Stochastic Gradient Descent\n",
    "Your function should have the signature\n",
    "linear_regression_sgd (X,y,learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_sgd(X,y,learning_rate,batch_size):\n",
    "    n_samples = (np.shape(X)[0])\n",
    "    p = np.shape(X)[1] # p is the number of variables in the multiple regression\n",
    "    b = np.ones((p+1,1)) #'guess' the initial values as zeros, +1 for the b_0 value\n",
    "    X = np.insert(X, 0, values=1, axis=1) # add a column of ones s.t. y=X*b\n",
    "    \n",
    "    # now the stochastic gradient descent:\n",
    "    for i in range(10000):\n",
    "        # randomly select batch_size sample\n",
    "        batch_ids = np.random.randint(np.shape(X)[0],size=batch_size)\n",
    "        #print('batch size: ', batch_ids)\n",
    "        X_batch = X[batch_ids,:]\n",
    "        #print(X_batch)\n",
    "        y_batch = y[batch_ids,:]\n",
    "        #print(y_batch)\n",
    "        \n",
    "        # adjust with that batch\n",
    "        prediction = np.dot(X_batch,b)\n",
    "        #print(prediction)\n",
    "        d_b = (-1)*np.dot(np.transpose(X_batch),(2*(y_batch-prediction))) # derivative w.r.t. b\n",
    "        b = b - 1/n_samples * learning_rate*d_b # b = b - learning_rate*gradient(f)\n",
    "    \n",
    "\n",
    "    #return (mean_squared_error_of_solution,list_of_optimum_parameters)\n",
    "    return ( np.mean((y-np.dot(X,b))**2) , b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.2000288087184836e-14, array([[2.99999932],\n",
       "        [1.0000005 ],\n",
       "        [1.99999995]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_sgd(X,y,0.01,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the quality of Government Dataset \n",
    "from here: https://www.qogdata.pol.gu.se/data/qog_bas_cs_jan18.csv.\n",
    "The data is described here\n",
    "load it into a pandas dataframe and select the following columns:\n",
    "\"cname\",\"wdi_lifexp\",\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('qog_bas_cs_jan18.csv')\n",
    "columnNames = [\"cname\",\"wdi_lifexp\",\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"]\n",
    "data = data[columnNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the correlation of all other variables with the life expectancy (wdi_lifexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wdi_lifexp     1.000000\n",
       "wdi_popden     0.171756\n",
       "gle_cgdpc      0.632859\n",
       "bti_acp        0.449749\n",
       "bti_pdi        0.181737\n",
       "fh_pair        0.666925\n",
       "al_ethnic     -0.555538\n",
       "al_language   -0.550292\n",
       "al_religion   -0.170274\n",
       "bti_aar        0.136264\n",
       "vdem_gender    0.431190\n",
       "bti_ci        -0.463416\n",
       "bti_foe        0.130552\n",
       "wdi_araland    0.037243\n",
       "wdi_forest     0.026779\n",
       "Name: wdi_lifexp, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor[\"wdi_lifexp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply your own implementations  (GD and SGD)\n",
    "To model the life expectancy from the population density and GDP per capita.\n",
    "Compare the results with what you get from scikit learn OR statsmodel libraries.\n",
    "\n",
    "For this subtask, just remove all countries with missing values in any of these three variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "# extract relevant data for our case\n",
    "XYData = data[['cname','wdi_popden','gle_cgdpc', 'wdi_lifexp']]\n",
    "\n",
    "# preprocess: drop NaN, scale\n",
    "XYData = XYData.dropna() \n",
    "X = XYData[['wdi_popden','gle_cgdpc']]\n",
    "X = preprocessing.scale(X)\n",
    "y = XYData[['wdi_lifexp']]\n",
    "y = preprocessing.scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5979993239144865, array([[2.94201082e-16],\n",
       "        [3.94906609e-02],\n",
       "        [6.24556484e-01]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_gd(X,y,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5982986377928871, array([[-0.00585511],\n",
       "        [ 0.04184107],\n",
       "        [ 0.60794555]]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_sgd(X,y,0.01,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.89817631e-16]), array([[0.03949066, 0.62455648]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "LinearRegression().fit(X, y).intercept_, LinearRegression().fit(X, y).coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build regression models to model the life expectancy (wdi_lifexp) in this dataset\n",
    "from all other mentioned variables.\n",
    "You can use scikit learn and/or statsmodels libraries for this task.\n",
    "Standardize variables and fill in missing values appropriately.\n",
    "Compare linear regression, Ridge regression and Lasso using k-fold-cross validation\n",
    "Test several parameters for the regularized regressions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assumption: leave out cname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"]]\n",
    "y = data[[\"wdi_lifexp\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/impute.html\n",
    "# https://scikit-learn.org/0.18/modules/preprocessing.html#imputation\n",
    "import sklearn\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "X = imp.fit_transform(X)\n",
    "y = imp.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sklearn.preprocessing.scale(X)\n",
    "y = sklearn.preprocessing.scale(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6882664 , 0.79996008, 0.70077573, 0.31323931, 0.57288526,\n",
       "       0.51966294, 0.59194857, 0.54073868, 0.4189656 , 0.6473073 ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
    "cv = ShuffleSplit(n_splits = k, test_size=0.1)\n",
    "lg = LinearRegression()\n",
    "cross_val_score(lg,X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24247205, 0.74391843, 0.71124449, 0.2861093 , 0.4863119 ,\n",
       "       0.65838797, 0.71009055, 0.56301846, 0.66896358, 0.68431846])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "lasso = Ridge()\n",
    "cross_val_score(lasso,X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38713716, 0.64992386, 0.5614686 , 0.62753713, 0.75392513,\n",
       "       0.50683957, 0.75905328, 0.35099827, 0.61660031, 0.28368014])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Ridge(alpha=0),X,y,cv=cv) # linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.55682328e-01, -1.10851528e-01,  4.31315191e-03, -3.05177322e-02,\n",
       "       -5.32554858e-02, -3.98832135e-03, -2.46758161e-02, -2.50289936e-05,\n",
       "       -1.07688815e-01, -2.60768162e-03])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Ridge(alpha=100000),X,y,cv=cv)  # coefficents go to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.70041334, 0.48501392, 0.66281824, 0.58699116, 0.617011  ,\n",
       "       0.6629976 , 0.6125895 , 0.58041788, 0.60254069, 0.71888772])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Ridge(alpha=1e-10),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.32652397e-03, -2.12285296e-01, -3.16084234e-02, -1.53736963e-04,\n",
       "       -8.24755112e-02, -5.89595520e-02, -2.46081627e-01, -3.82267872e-03,\n",
       "       -1.18363905e-01, -1.75649063e-02])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lasso regression\n",
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()\n",
    "cross_val_score(lasso,X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58376861, 0.61597261, 0.68833639, 0.51883046, 0.77254637,\n",
       "       0.67285183, 0.64478344, 0.48576241, 0.59639056, 0.55148189])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Lasso(alpha=1e-15),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21386891, 0.81958361, 0.5454186 , 0.61071232, 0.1717096 ,\n",
       "       0.57845261, 0.51944198, 0.64159504, 0.683813  , 0.74992033])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Lasso(alpha=1e-5),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1865865 , 0.5055625 , 0.72825153, 0.59185169, 0.78917682,\n",
       "       0.59664045, 0.59222486, 0.46265087, 0.71035191, 0.83755993])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Lasso(alpha=1e-10),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33812857, 0.53014303, 0.51518985, 0.46217371, 0.54196854,\n",
       "       0.63625363, 0.50313216, 0.68570864, 0.52509479, 0.52472505])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(Lasso(alpha=1e-12),X,y,cv=cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Forward and Backward Selection algorithms\n",
    "And apply it to the (given subset of variables of the) Quality of Government dataset.\n",
    "Compare the results of Forward and Backward selection with each other.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X, features):\n",
    "    transformed = X[features]\n",
    "    transformed = imp.fit_transform(transformed)\n",
    "    transformed = sklearn.preprocessing.scale(transformed)\n",
    "    return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardSelection(X,y,available_features, current_features):\n",
    "    result = []\n",
    "    while(len(available_features)>0):\n",
    "        #preprocess y\n",
    "        y = imp.fit_transform(y)\n",
    "        y = sklearn.preprocessing.scale(y)\n",
    "\n",
    "        highestScore= -500 #smallestError = 10000\n",
    "        bestFeature = \"wdi_popden\"\n",
    "        for feature in available_features:\n",
    "            current_features.append(feature)\n",
    "\n",
    "            # preprocess X[current_features]\n",
    "            transformed = preprocess(X,current_features)\n",
    "\n",
    "            #curError = linear_regression_gd(transformed,y, alpha)[0]\n",
    "            curScore = np.mean(cross_val_score(lg,transformed,y,cv=cv))\n",
    "            #print(curScore)\n",
    "            #print(curError)\n",
    "            current_features.remove(feature)\n",
    "            #print(curError<smallestError)\n",
    "            #if (curError<smallestError):\n",
    "            if (curScore>highestScore):\n",
    "                bestFeature = feature\n",
    "                #smallestError = curError\n",
    "                highestScore=curScore\n",
    "        \n",
    "        result.append(highestScore)\n",
    "        available_features.remove(bestFeature)\n",
    "        current_features.append(bestFeature)\n",
    "        #print(current_features)\n",
    "        print('current features:', current_features)\n",
    "        #print('according error:', smallestError)\n",
    "        print('according score:', highestScore)\n",
    "    maxIndex = np.argmax(result)\n",
    "    print(result)\n",
    "    print(maxIndex)\n",
    "    return current_features[:maxIndex+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "## K-fold cross-validation (10%, 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current features: ['fh_pair']\n",
      "according score: 0.29633143513589927\n",
      "current features: ['fh_pair', 'bti_aar']\n",
      "according score: 0.5523356309614205\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc']\n",
      "according score: 0.5724678575271285\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic']\n",
      "according score: 0.5922330451717627\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language']\n",
      "according score: 0.6496532764376307\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi']\n",
      "according score: 0.6608953741951082\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci']\n",
      "according score: 0.638442759593848\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe']\n",
      "according score: 0.683577175346125\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp']\n",
      "according score: 0.7093487766970169\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp', 'vdem_gender']\n",
      "according score: 0.7182125213188255\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp', 'vdem_gender', 'wdi_araland']\n",
      "according score: 0.5954675221993193\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp', 'vdem_gender', 'wdi_araland', 'al_religion']\n",
      "according score: 0.5681600548559003\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp', 'vdem_gender', 'wdi_araland', 'al_religion', 'wdi_popden']\n",
      "according score: 0.622911032441867\n",
      "current features: ['fh_pair', 'bti_aar', 'gle_cgdpc', 'al_ethnic', 'al_language', 'bti_pdi', 'bti_ci', 'bti_foe', 'bti_acp', 'vdem_gender', 'wdi_araland', 'al_religion', 'wdi_popden', 'wdi_forest']\n",
      "according score: 0.593408549798427\n",
      "[0.29633143513589927, 0.5523356309614205, 0.5724678575271285, 0.5922330451717627, 0.6496532764376307, 0.6608953741951082, 0.638442759593848, 0.683577175346125, 0.7093487766970169, 0.7182125213188255, 0.5954675221993193, 0.5681600548559003, 0.622911032441867, 0.593408549798427]\n",
      "9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fh_pair',\n",
       " 'bti_aar',\n",
       " 'gle_cgdpc',\n",
       " 'al_ethnic',\n",
       " 'al_language',\n",
       " 'bti_pdi',\n",
       " 'bti_ci',\n",
       " 'bti_foe',\n",
       " 'bti_acp',\n",
       " 'vdem_gender']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"]\n",
    "forwardSelection(data[features], data[['wdi_lifexp']],features,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwardSelection(X,y,removed_features, current_features):\n",
    "    result = []\n",
    "    #preprocess y\n",
    "    y = imp.fit_transform(y)\n",
    "    y = sklearn.preprocessing.scale(y)\n",
    "    # backward selection\n",
    "    while(len(current_features)>1):\n",
    "        lowestScore= 500 #smallestError = 10000\n",
    "        worstFeature = \"wdi_popden\"\n",
    "        \n",
    "        for feature in current_features:\n",
    "            current_features.remove(feature)\n",
    "            # preprocess X[current_features]\n",
    "            transformed = preprocess(X, current_features)\n",
    "            # calculate score for current feature\n",
    "            curScore = np.mean(cross_val_score(lg,transformed,y,cv=cv))\n",
    "            current_features.append(feature)\n",
    "            # find lowest score\n",
    "            if (curScore<lowestScore):\n",
    "                worstFeature = feature\n",
    "                lowestScore = curScore\n",
    "        result.append(np.mean(cross_val_score(lg,preprocess(X,current_features),y,cv=cv)))\n",
    "        current_features.remove(worstFeature)\n",
    "        removed_features.append(worstFeature)\n",
    "        print('current features:', current_features)\n",
    "        #print('according error:', smallestError)\n",
    "        print('worst score before:', lowestScore)\n",
    "    maxIndex = np.argmax(result)\n",
    "    print(result)\n",
    "    print(maxIndex)\n",
    "    print(removed_features)\n",
    "    return removed_features[maxIndex:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current features: ['gle_cgdpc', 'bti_pdi', 'al_ethnic', 'al_religion', 'vdem_gender', 'bti_foe', 'wdi_forest', 'bti_acp', 'al_language', 'bti_ci', 'wdi_popden', 'bti_aar', 'fh_pair']\n",
      "worst score before: -0.04627996323580156\n",
      "current features: ['bti_pdi', 'al_religion', 'bti_foe', 'bti_acp', 'bti_ci', 'bti_aar', 'gle_cgdpc', 'vdem_gender', 'al_language', 'fh_pair', 'wdi_forest', 'al_ethnic']\n",
      "worst score before: 0.3255208769220078\n",
      "current features: ['al_religion', 'bti_acp', 'bti_aar', 'vdem_gender', 'fh_pair', 'al_ethnic', 'bti_foe', 'gle_cgdpc', 'wdi_forest', 'bti_ci', 'al_language']\n",
      "worst score before: 0.47706751942742825\n",
      "current features: ['bti_acp', 'vdem_gender', 'al_ethnic', 'gle_cgdpc', 'bti_ci', 'al_religion', 'wdi_forest', 'bti_aar', 'al_language', 'bti_foe']\n",
      "worst score before: 0.48036916912875105\n",
      "current features: ['vdem_gender', 'gle_cgdpc', 'al_religion', 'bti_aar', 'bti_foe', 'wdi_forest', 'bti_acp', 'al_language', 'bti_ci']\n",
      "worst score before: 0.486207572908787\n",
      "current features: ['gle_cgdpc', 'bti_aar', 'wdi_forest', 'al_language', 'vdem_gender', 'bti_foe', 'bti_ci', 'bti_acp']\n",
      "worst score before: 0.47003850538977376\n",
      "current features: ['bti_aar', 'al_language', 'bti_foe', 'bti_acp', 'wdi_forest', 'bti_ci', 'vdem_gender']\n",
      "worst score before: 0.3450527751752165\n",
      "current features: ['al_language', 'bti_acp', 'bti_ci', 'bti_aar', 'wdi_forest', 'bti_foe']\n",
      "worst score before: 0.1991972681768308\n",
      "current features: ['bti_acp', 'bti_aar', 'bti_foe', 'bti_ci', 'wdi_forest']\n",
      "worst score before: 0.0201784886483372\n",
      "current features: ['bti_aar', 'bti_ci', 'bti_acp', 'wdi_forest']\n",
      "worst score before: 0.02958639816624974\n",
      "current features: ['bti_ci', 'wdi_forest', 'bti_acp']\n",
      "worst score before: 0.008157392242176983\n",
      "current features: ['wdi_forest', 'bti_ci']\n",
      "worst score before: -0.0737510190202208\n",
      "current features: ['bti_ci']\n",
      "worst score before: 0.09178344073825515\n",
      "[0.48479895207357904, 0.5708913866616044, 0.6238324960510357, 0.59805654109067, 0.292995299103246, 0.5303262680859531, 0.549174652849253, 0.40695012189126534, 0.4245579229556585, 0.08588032327539656, 0.0671565113885548, 0.009018142210450487, -0.0025943264876487015]\n",
      "2\n",
      "['wdi_araland', 'wdi_popden', 'bti_pdi', 'fh_pair', 'al_ethnic', 'al_religion', 'gle_cgdpc', 'vdem_gender', 'al_language', 'bti_foe', 'bti_aar', 'bti_acp', 'wdi_forest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['bti_pdi',\n",
       " 'fh_pair',\n",
       " 'al_ethnic',\n",
       " 'al_religion',\n",
       " 'gle_cgdpc',\n",
       " 'vdem_gender',\n",
       " 'al_language',\n",
       " 'bti_foe',\n",
       " 'bti_aar',\n",
       " 'bti_acp',\n",
       " 'wdi_forest']"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\"wdi_popden\",\"gle_cgdpc\",\"bti_acp\", \"bti_pdi\", \"fh_pair\", \"al_ethnic\",\"al_language\",\"al_religion\",\"bti_aar\",\"vdem_gender\",\"bti_ci\",\"bti_foe\",\"wdi_araland\", \"wdi_forest\"]\n",
    "backwardSelection(data[features], data[['wdi_lifexp']],[],features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
